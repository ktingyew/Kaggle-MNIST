{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt, matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('input/train.csv')\n",
    "\n",
    "# Training data is s.t. each entry (row) represents an image. 1 label column, + 784 pixel values.\n",
    "\n",
    "raw.head(5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data is 42000 images. That's a lot. We will have to select a subset randomly using pandas' sample().\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 42000\n",
    "p = 0.85\n",
    "\n",
    "train = raw.sample(n=SIZE,         # default behaviour is s.t. no one row is sampled twice. \n",
    "                   random_state=1) # random_state ensure reproducibility\n",
    "train = train.reset_index()\n",
    "train.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,   0,  93, 155,  80,  89, 248, 145,   2,  11, 173, 254, 183,\n",
       "       195, 253, 209,   6,  13, 218, 211, 189, 125, 184, 194,  12,  96,\n",
       "       207,  59, 128, 249, 212,  47,  63, 223, 143,  33, 243, 177, 140,\n",
       "       113, 168,  15, 235, 216, 204, 124, 105, 231, 229, 101, 149,  95,\n",
       "       174, 240,  31, 116,  99, 122,  90,  45, 226, 238,  25,  20,   3,\n",
       "         8, 180, 224,  69, 232,  50, 245,  56,  41, 252, 120, 236, 178,\n",
       "        91, 228, 164, 110, 217, 123,  26, 205, 156,  73], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to confirm that the values of each pixel can vary from 0 to 255\n",
    "train.iloc[1].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the y out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['label']\n",
    "y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train / 255\n",
    "train;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalised to [0,1]\n",
    "\n",
    "train.iloc[1].unique();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset to train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, train_size=p, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35700, 784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, you would use Data Augmentation to **expand** on your dataset. If you have a lot to begin with, then this is quite pointless?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            zoom_range = 0.10, # Randomly zoom image \n",
    "            width_shift_range=0.08,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.08,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=False,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "# Note this does not perform a transformation inplace. You have to 'flow' it out.\n",
    "X_train_3d = X_train.values.reshape(-1, 28, 28, 1) # '1' is for greyscale channel. If RGB, then '3'.\n",
    "datagen.fit(X_train_3d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data augmentation, I choosed to :\n",
    "\n",
    "- Randomly rotate some training images by 10 degrees\n",
    "- Randomly Zoom by 10% some training images\n",
    "- Randomly shift images horizontally by 10% of the width\n",
    "- Randomly shift images vertically by 10% of the height\n",
    "- I did not apply a vertical_flip nor horizontal_flip since it could have lead to misclassify symetrical numbers such as 6 and 9.\n",
    "\n",
    "Once our model is ready, we fit the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing an Image\n",
    "- Since the image is currently one-dimension, we load it into a [numpy array][1] and [reshape][2] it so that it is two-dimensional (28x28 pixels)\n",
    "- Then, we plot the image and label with matplotlib\n",
    "\n",
    "\n",
    "  [1]: https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html\n",
    "  [2]: https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_train.iloc[0].values.reshape(28,28) \n",
    "img;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(img, \n",
    "               cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (Takes a lot of time!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling (On Purely Non-augmented Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9747619047619047"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(verbose=True)\n",
    "clf.fit(X_train, y_train.values)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling (On Purely Augmented Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_iter = datagen.flow(x=X_train_3d, y=None, batch_size=int(SIZE*p), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented = np_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented = X_train_augmented.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "to_execute = True\n",
    "\n",
    "if to_execute:\n",
    "    clfa = svm.SVC(verbose=True)\n",
    "    clfa.fit(X_train_augmented, y_train.values)\n",
    "    print(clfa.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736507936507937"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Our Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clfa.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(clf, 'clf.joblib') \n",
    "dump(clfa, 'clfa.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data and Normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = test.iloc[4].values.reshape(28,28) \n",
    "g = plt.imshow(img, \n",
    "               cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_a = clfa.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format for Submission\n",
    "\n",
    "### For The Unaugmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name='ImageId'\n",
    "df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28000</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label\n",
       "ImageId       \n",
       "1            2\n",
       "2            0\n",
       "3            9\n",
       "4            9\n",
       "5            3\n",
       "...        ...\n",
       "27996        9\n",
       "27997        7\n",
       "27998        3\n",
       "27999        9\n",
       "28000        2\n",
       "\n",
       "[28000 rows x 1 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index+=1\n",
    "df.columns=['Label']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28000</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label\n",
       "ImageId       \n",
       "1            2\n",
       "2            0\n",
       "3            9\n",
       "4            9\n",
       "5            3\n",
       "...        ...\n",
       "27996        9\n",
       "27997        7\n",
       "27998        3\n",
       "27999        9\n",
       "28000        2\n",
       "\n",
       "[28000 rows x 1 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a = pd.DataFrame(prediction_a)\n",
    "df_a.index.name='ImageId'\n",
    "df_a.index+=1\n",
    "df_a.columns=['Label']\n",
    "df_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save into csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output/pred.csv', header=True)\n",
    "df_a.to_csv('output/pred_a.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-keras_gpu]",
   "language": "python",
   "name": "conda-env-.conda-keras_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
